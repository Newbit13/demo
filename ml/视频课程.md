学习笔记，以视频集数为标题，总结每集的收获和知识点

[黑马最热门的人工智能机器学习及机器视觉终于来了！从入门到精通（附赠课件资料+笔记](https://www.bilibili.com/video/BV1wy4y1T78o)
这个视频TensorFlow用的是1.x的版本，从网上资料来看，目前2.x版本中已经废弃了很多1.x的api，并且操作上更加简洁，所以这个视频我先暂时不看了

# p2学习笔记
## 深度学习与机器学习的区别
特征提取方面：
    机器学习需要自己提取特征，这需要大量领域专业知识；
    深度学习（通常由多个层组成），通过大量数据训练自动得到模型，适用于难提取特征的图像，语音，自然语言领域（应用场景）；

数据量方面：
    深度学习一般数据量越大结论越准确，而机器学习在一定数据量后达到一个相对稳定的准确率，并不会随着后面数据量的增大而表现更佳。
    深度学习需要的算力也比较大

算法代表
    机器学习：朴素贝叶斯、决策树
    深度学习：神经网络



个人总结：在容易提取特征的领域，采用机器学习的方法，通过手动提取特征，在效率和效果方面应该是表现不错的。深度学习需要的数据量应该较大，提取模型的成本也比较大。所以不能说 深度学习 就比 机器学习 优

深度学习框架：github start关注度历年来前二分别是TensorFlow，Caffe 



[[中英字幕]吴恩达机器学习系列课程](https://www.bilibili.com/video/BV164411b7dx)

笔记
# p1
机器学习应用领域广泛，如自动驾驶，基因测序，研究人脑思考方式，搜索引擎推荐，图片分类，识别垃圾邮件等

# p2
介绍一般对于机器学习的定义，给一个任务T,通过经验E,得到性能度量P(我认为算做正确的概率)
这课程会教很多不同类型的学习算法，最主要的两类是 监督学习(supervised learning)和无监督学习（其他的经常听到的有，强化学习，推荐系统等）
简单的说 监督学习是我们让机器学会处理某一件事；无监督学习是我们让机器自己学习

# p3 
回归问题，值是连续的
分类问题，值是离散的
总结：通过值去判断要用把问题归为哪一类（进而选择合适的算法）
这些属于监督学习的范围

# p4
将无监督学习
中监督学习的例子中，我们会被告知什么是良性肿瘤，什么是恶性的；
现在我们拿到一推数据，没人告诉我们这些数据的意义，这时候就属于用到无监督学习的范围了
提到 
聚类算法，将数据归为一个簇一个簇的（应用例子：谷歌新闻：每天收集大量新闻并分为各种专题；给一推基因数据让其分类，类型我们事先未知；根据邮件判断哪些人可能是朋友；通过客户数据找到不同的细分市场）
鸡尾酒会算法（应用例子：耳机降噪），实际上一行算法：[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x');
svd：singular value decomposition 奇异值分解（线性代数常规函数）


提到Octave、Matlab这样的软件
作者推荐使用Octave，在硅谷很多人会先用Octave建立软件原型，因为在Octave中实现这些学习算法的速度很快，在这个软件中，例如svd函数也内置了，不然如果自己用c++或者java库我们需要自己写很多代码，当在软件里可以运行时，我们再将其迁移到其他环境（java，c++等）下，这样效率更高（根据弹幕有歧义，说现在python可以很方便的现实功能）

# p5
了解监督学习的过程
1. Traning Set训练集 --输入到>> Learning Algorithm学习算法 --得到>> h(hypotheis)假设函数
2. 输入值通过->h->输出预测值
# p6 代价函数
如果假设函数是这个形式： hθ(x) = θ0 + θ1x;
通过找到最小的值：minimize_θ0θ0  J(θ0,θ0) =  (1/2m) * 0Σi=m (h(x^(i)) - y^(i))^2的平方差和来确定参数值 (这个公式算我手打的...可能不好看，我用_标识后面的符号在底部。。。)

这个1/2m是为了开导时抵消掉平方，对优化结果来说无影响（弹幕提供）
（微积分有点忘了，但是这里感悟是用积分方程可以减低计算量）
微积分有公式的，比如基本的导数公式中 x^u = u*x^(u-1)

J(θ0,θ1) 在这里就是代价函数Cost function，或者叫做lost function。这里这个具体的函数叫做squared error function

这个squared error function对大多数回归问题是个合理的选择（常用）

# p7 代价函数2
作者简化了一下函数：hθ(x) = θ1x;然后将x值代进代价函数中，把θ1作为变量
画出了θ1与结果的图像变化图（可以看到变化的规律，嗯...没什么，算是加深一下对公式作用的理解吧）

# p8 代价函数3
假设函数换回这个形式： hθ(x) = θ0 + θ1x;
然后画图

提到 contour plots等高线图
如果是将x带入，那么由θ0，θ1，该代价函数的值分别坐标x,y,z轴，由此组成的立体图像会呈现一个碗状，在平面中我们可以用等高线去表示

从目前简单的例子可以体会到如何一步步寻找最小值（目前使用眼睛观察的），这让我想起梯度下降，动量等模糊概念，这些概念的存在意义就是为了加速得到最小值。而不是先遍历所有可能（遍历所有的值，在这就是画出三维立体图）

多维度参数想可视化就没那么简单了

# p9 梯度下降
gradient descent梯度下降，是一个很常用的算法。不仅可用在最小化线性回归的代价函数上

按照两个参数来举例：θ0、θ1
大概思路：
首先给θ0、θ1分别一个初始值，随便什么值都行。例如θ0 = 0、θ1 = 0
不断改变θ0、θ1，使得 代价函数J(θ0、θ1)变小，直到找到最小值或局部最小值（这很明显跟初始位置及“山峰”形状有关）

梯度下降算法：
重复更新参数θj直至收敛
repeat until convergence{
    θj :=θj - α(∂/∂θj)J(θ0、θ1)  (simultaneously update j=0 and j=1)
}
在这就是同时更新θ0和θ1

:= 表示赋值（如果单纯用=，在这里是断言，会得到true或false）
α 学习率,是一个数值，在梯度下降中，意味着我们迈出多大的步子，值大意味着梯度下降很迅速
(∂/∂θj)J(θ0、θ1) 是一个导数项（没见过偏导数的话看一下下面提供的参考资料）  

(∂/∂x)f(x,y)，表示函数f(x,y)对变量x的偏导
(∂/∂y)f(x,y)，表示函数f(x,y)对变量y的偏导

参考资料
[第二节 偏导数](http://netedu.xauat.edu.cn/jpkc/netedu/jpkc/gdsx/homepage/5jxsd/51/513/5308/530802.htm)
在资料中可以了解到，求偏导数跟求导数方法一样，先把其他变量看成常量，再用求一元函数的导数的方法去求导

# p10 梯度下降算法里那个导数项的相关内容
derivative 导数
导数和偏导数是什么？（惨，大学数学给忘了）这里我百度了一下 [偏导数、微分、以及导数到底有什么关系和区别？](https://www.zhihu.com/question/265021971)


一个函数的导数，就是函数在图像上的斜率
偏导数，偏是局部的意思，一般是是指一个多元函数，其他变量都确定时，只对有剩余一个不确定的变量函数的导数。在几何意义上，就是一个点在任意确定的面上的切线的斜率。（想象一下，一个三维物体上的一个点，是不是有无数条切线，而二维平面图上，一条曲线是不是只有一条切线。所以求一条曲线的切线的斜率和求一个三维物体的其中一条切线的斜率就是导数和偏导数的区别）

在简化的代价函数J(θ1)中，对其θ1的偏导数就是 (∂/∂θ1)*J(θ1),这里是我个人理解的写法，一般不会这么表示，一般一元函数的导数写作J'(θ1)

α 学习率，如果太小，那么需要很多步才能到达局部低点；如果太大，可能会一次性越过最低点，导致无法收敛，也就是一直无法达到局部低点

随着θ1的更新，(∂/∂θ1)*J(θ1)作为斜率的值越来越小，所以θ1更新的幅度越来越小，最终我们会无限接近最低点。


## p1~p10 总结

对于一个线性的问题，
我们需要得到一个函数y=f(x),这样我们可以通过输入任意x得到答案y
这时候函数的形状可能有很多种，那么我们只能先假设，假设这个函数是直线，然后大概长这样：
f(x) = a + bx; a,b是一个固定的值，然后确定要用的损失函数，也就是代价函数，把a,b作为变量，通过h(a,b) 这个代价函数来确定a，b的值。

那么这里用什么形式的代价函数，用什么方法确定a，b的值，就是我们学习的重点了。
这几节课里我学习了squared error function在回归问题上作为代价函数效果不错，然后学习了梯度下降这种函数方法是如何来对这种代价函数进行处理的

所以目前我算是掌握了一个对于这种回归问题如何处理的整体思路。

    个人思考：
    目前感受到的就是算法、数学的魅力，但是智能还算不上，到不如说“自动”，就像你问计算机1+1，他跟你说等于2，那么分类，预测，只是相当于把1+1换成了更加复杂的东西，本质上还是计算方式

    那么神经网络，深度学习是不是毕竟接近我们印象中的智能呢？其实他也是一种算法，而我现在就在了解其具体的算法。这就是所谓的“人工智能”，跟人类的拥有复杂感情相比好像关系没那么明显或者说没有关系。但是仔细想想，大多数感情，感觉都是身体里的各种器官，激素的作用和变化引起“感觉”，“感觉”跟“人工智能”合在一起才是个完整的人。那么现在思路就更加清晰了，我在学的是“智能”，就是所谓的让计算机更加聪明的方法。所以重点在于“智能”，而不在于“人”上。“智能”目前是生物才具有的。所以研究神经网络的应用最接近“智能”了吧

# p11
这节课将代价函数带入并求偏导数的值（证明方法略）：

注意要同时更新θ0和θ1
repeat until convergence{
    θ0 :=θ0 - α * (1/m) * i=1 Σ m (hθ(xi)-yi)
    θ1 :=θ1 - α * (1/m) * i=1 Σ m (hθ(xi)-yi) * xi
}

xi代表训练集中第i个x的数据，m代表有训练集中有m个数据

用梯度下降法有个缺点就是得到的是局部底部，然而这里代价函数是线性回归方程，得到的三维图像是一个碗状的图形，这图形有个术语叫做convex function 凸函数

凸函数不会存在只得到局部最低点这个问题，它只有一个全局最优解

给这种梯度下降一个名字，叫做“Batch” Gradient Descent，Batch在这里表示每一步梯度都需要使用到所有的训练集数据（那个i=1 Σ m ）

# p12
提到矩阵与向量的概念,表达方式。（这个看视频，我不好表达）
矩阵，就像二维数组，维数就是行数*列数，书写形式有R^(2*2)

向量，就像一维数组，一个n*1的矩阵，可以写成R^n

# p13
矩阵加法，就是对应元素相加，并且得是相同结构的矩阵才能相加
矩阵和标量（就是实数）的乘法，就是每个对应的元素与标量相乘
# p14 矩阵乘法
先讲了个特殊例子， 矩阵跟向量的乘法：例中R^(3*2) x R^(2*1) 得到一个R^(3*1)的矩阵，那么看来要相乘的话，第一个矩阵的列数要跟第二个矩阵的行数相同

作者举了一个房子价格的例子，用矩阵跟向量的乘法，可以将不同房子大小这个变量发到矩阵中，配合价格函数构造出一个矩阵乘向量的模型（对这种计算的表达方式我觉得十分的miao），这样做的好处在于用更加简洁的公式表达了想法（相当于简化了代码,目前我具体感受不到）

# p15 矩阵与矩阵相乘
了解这个可以在线性回归中同时计算θ0和θ1而不用梯度下降函数（作者说的）

矩阵与矩阵相乘可以看作矩阵跟各个向量相乘的结果，拼起来（所以还是遵循一个规则：第一个矩阵的列数要跟第二个矩阵的行数相同）
通过举例多个预测价格函数（上一集将跟向量相乘时是举例一个价格函数），来体现矩阵与矩阵相乘的表达方式（miao啊又）

# p16
设计矩阵运算的一些特性：
不符合交换律（commutative）
符合结合律（associative）

单位矩阵（可以有多种维数的），只有Rii上的值为1，其他为0。表述为I(或者I_n*n),单位矩阵与矩阵相乘满足交换律  注意：交换后的单位矩阵的维数不一定跟原来的一致，切记

# p17
矩阵的逆运算(inverse operation)、矩阵的转置运算(transpose operation)

    A*A^-1 = I 这个A^-1就是矩阵A的逆矩阵。只有m*m的这种方阵才有逆矩阵 有一些特殊的方阵也是没用逆矩阵的，作者这里不讨论
不存在逆矩阵的矩阵有个专有名词叫做 奇异矩阵 singular matrix或者退化矩阵 degenerate matrix

A^T表示矩阵A的转置矩阵，具体表现为矩阵里的元素位置A_ij变成A_ji（第一行变成第一列，以此类推）

# p18
回到之前房屋价格预测的例子，如果这时候信息多了（特征量多了），原先只考虑房子大小跟价格的关系，现在可以考虑的因素有大小，楼层，房龄，房间数量。

那么重新定义一下：
n：特征数
x^(i)第i个训练集，是有一组特征值组成的向量
x^(i)_j 第i个训练集的第j个特征值（这里我写的格式不规范...）

代价函数变成了hθ(x1,x2,x3,x4) = θ0 + θ1x1 + θ2x2 + θ3x3 + θ4x4;(多元多变量线性回归假设)
通过构建 θ变量组成的向量 和x标量组成的向量，可以用来表示hθ(x1,x2,x3,x4)

# p19
    Hypothesis:hθ(x) = θ^T*x = θ0*x0 + θ1*x1 + θ2*x2 + ... + θn*xn  (这里θ和x分别是指向量)
    Parameter:θ0,θ1,...,θn (我们这里会用θ这个向量表示这一串变量)
    Cost function: J(θ0,θ1,...,θn) = (1/2m) * i=1Σm (hθ(x^(i)) - y^(i))^2   （同理J(θ0,θ1,...,θn)写成J(θ)）

n个特征时的梯度下降公式（见视频吧...）

# p20
梯度下降的实用技巧(提高效率，减少迭代速度)
技巧方法一：特征缩放
将特征缩小有利于更快的收敛，相反特征直接差距大会让等高线看起来向被压缩一样，并且梯度下降的路径会变得曲折，导致收敛速度慢。
我们需要在缩小后的各特征的值范围相接近，比如缩小后值都是-1~1之间

在特征缩放时，我们有时候还会进行 均值归一化 Mean normaliztion
xi变成xi-μi，这里μi表示xi的平均值

公式（xi-μi）/ si ,si是最大值-最小值得到的，叫做范围

# p21
提到通过观察迭代次数和代价函数的值组成的图像，来判断梯度下降方法是否有在正常工作。

如果不正常（例如代价函数的值随迭代次数增加而增加或者上下上下反复波动），意味着你应该使用较小的学习率α

我们会尝试使用不同的学习率α来观察效果

实际工作中，作者喜欢（觉得合适）每次3倍的涨幅对不同α进行尝试

# p22
作者想告诉我们一些可选择的特性，还有如何得到不同的学习算法（很不错的感觉），因为选择当选择合适的特征后，算法往往才会非常有效

提到多项式回归 polynomial regression,它让我们可以使用线性回归的方法来拟合复杂的函数甚至是非线性函数

将特征进行整合，可以得到有利于结果的更加有用的特征（关于这点作者举例如果你得到房子的长跟宽，我们不一定要把长跟宽分别作为特征，而将其相乘计算成房子面积这个特征会更有效）
通过定义新的特征，我们可能会得到更好的模型

接下来会了解到一些算法可以帮我们选择要用什么模型，要用什么多项式函数

# p23
作者提供一种正规方程来求得线性方程的最优值，而不是使用梯度下降算法


求最小化θ的公式（证明作者未给）：
θ = (X^T * X)^(-1) * X^T *y 其中X是一个m条数据 * n个特征构成的m * (n+1)的一个矩阵。y是由m条结果数据 构成的向量
这个公式能得到一个由m条θ数据 构成的向量

对比：
假如有m个训练样本，n个特征.
| 梯度下降 | 正规方程(Normal Equation) |
|---|---|
|需要选择学习率α|不用选择学习率|
|需要很多次迭代|不用使用迭代|
|即使n很大，也能很好的进行计算|当n很大时很慢,O(n^3)|


作者提到自己，一般小于10^4,现代计算机都能很快算出，所以会选正规方程，当`10^4<n<10^6`作者会犹豫下，然后选择正规方程，当大于100万，作者会选择梯度下降或者其他算法

# p24 正规方程在矩阵不可逆情况下的解决方法
作者提到出现逆矩阵的概率其实不大。
Octave软件里有两个函数可以求解矩阵的逆：pinv()和inv()
pinv是伪逆（pseudo-inverse），即使某个矩阵不可逆，用pinv也可以算出θ值

什么时候矩阵(X^T * X)会不可逆，

1. Redundant features(linearly dependent)
多余特征（线性依赖）
具体例子为，比如有两个特征，一个是表示房子的平方米，一个是房子的平方英寸，这两特征有线性关系，因为米跟英寸可以相互转换。
2. 太多特征（m<=n）
这时候可以选择删掉一些特征，或者使用regularization(正规化方法)（后面讨论）

# p26 Octave的基本操作
接下来是Octave语法的学习
Octave可以快速实现算法的原型（当你想构建大型的机器学习项目时），测验自己的想法是否有效，如果可行，咱们再可以用c++或者java等语言来实现，提高开发效率
我简单了解下语法就好，毕竟看弹幕提到目前是python在主导机器学习项目。
```Octave
% 表示注释
== 等于
~= 不等于
不正确时返回0，正确返回1
&& 与
|| 或
xor(1,0) %异或运算，ans = 1
a=3 % semicolon supressing output 这样可以阻止打印输出
A = [1 2;3 4;4 5] %这样会生成一个三行两列的矩阵A
v = [1 2 3] %这是一个1*3的矩阵
v = [1;2;3] %这是一个3*1的列向量
v = 1:0.1:2 %这是一个1*11的矩阵，是行向量，1是起始点，0.1是步长，2是终点
v = 1:6 %一个1到6的行向量
ones(2,3) %生成一个2*3的，元素都是1的矩阵；zeros(1,3)会生成一个1*3的零矩阵
w = rand(1,3) %生成一个1*3的内容随机的行向量
w = randn(1,3) %生成一个1*3的内容随机但服从高斯分布的行向量
hist(w) %根据w的值画出直方图，hist(w，50)画出的直方图中有50条柱子
eye(4) %生成一个4*4的单位矩阵
```
Octave控制台里输入下面代码可以更改提示符：
PS1('>> ');  

# p27 加载、移动数据
```Octave
size(A) %返回矩阵A的大小，其实也是个行向量
size(A,1) %返回矩阵A的行数大小 ，size(A,2)返回列数
length(A) %返回矩阵维度较大的那个

load featuresX.dat %featuresX.dat里假设有训练数据，这时候我们就有了featuresX这个变量
load('featuresX.dat') %加载数据另一种方法
v = featuresX(1:10) %得到矩阵的前10个
save hello.mat v; %将v变量的内容保存到hello.mat这个文件中
who %显示所有内存中的变量
whos %显示更详细的变量信息
clear xxx %删除xxx这个变量，单独用clear是删除全部变量
A(3,2) %会得到A矩阵的第3行第2个
A(3,:) %会得到A矩阵的第3行所有元素
A([1,3],:) %会得到A矩阵的第1行和第3行所有元素
A(:,2) = [10;11;12] %对A矩阵的第二列进行赋值
A = [A,[10;11;12]] %在A的右侧增加一列
A(:) %将所有元素，变成一个列向量
C = [A;B] %B放到A的下面
```

# p28 计算数据
```Octave
A*B %矩阵相乘
A .* B %A的每个元素和B的每个元素一一对应相乘
A .^2  %A的每个元素进行平方计算
log(A) %对A的每个元素进行对数运算
exp(A) %对A的每个元素进行以e为底，元素为指数的幂运算
abs(A) %求A中所有元素的绝对值
A + 1 %A的所有值都加上1
A'   %得到A的转置矩阵
max(a)  %返回最大的值，当A是矩阵时会返回每一列的最大值
[val,index] = max(a) %得到最大值跟索引
a < 3 %返回一个由0或者1构成的结构，相当于把a的每个元素与3进行比较并得到结果
find(a < 3) %得到满足条件的索引，从1开始数
magic(3) %得到一个矩阵，这个矩阵每一行，每一列，还有对角线上的值，加起来都相同，一般拿来生成随机矩阵用（基本在机器学习中不会用到）
[r,c] = find(A >= 7) %会得到r和c两个列向量，两列向量的元素分别对应表示第几行，第几列的值满足条件
sum(a) %得到向量a的每个元素加起来的值
sum(a,1) %得到一个行向量，是矩阵a的每一列的总和；sum(a,2)就是求每一行的总和，得到的是一个列向量
prod(a) %product，表示a的每个元素相乘的积
floor(a)、ceil(a) %分别是向下取整和向上取整
rand(3) %得到3*3的随机矩阵
max(A,[],1) %得到每一列最大的值
max(A,[],2) %得到每一行最大的值
max(max(A)) %得到矩阵的一个最大值，max(A(:))也可以
A .*eye(9) %得到一个矩阵，除了对角线，其他值都是0
flipud(eye(9)) %得到一个垂直翻转的矩阵
pinv(A) %得到伪逆矩阵
```

# p29 数据绘制
```Octave
t=[0:0.01:0.98];
y1 = sin(2*pi*4*t);
plot(t,y1); %t为x轴的值，y1为y轴的值，画出一个图来
y2 = cos(2*pi*4*t);
plot(t,y2);
%这时候会覆盖之前的图
% 用hold on就不会清空之前的图
plot(t,y1);
hold on;
plot(t,y2,'r'); %给余弦值一个红色
xlabel('time') %给横轴一个标签值
ylabel('value') %同理
legend('sin','cos') %添加图例
title('my plot') %添加标题
print -dpng 'myPlot.png' %将图表保存起来
close %关闭图表
%画两个图并且不会相互影响
figure(1);plot(t,y1)
figure(2);plot(t,y2) 
subplot(1,2,1) %画一个1*2的格子，然后使用第一个格子
plot(t,y1) %这时候图表会画在第一个格子里
subplot(1,2,2) %选择使用第二个格子
plot(t,y2) %这时候图表会画在第二个格子里
axis([0.5 1 -1 1]) %设置前两个设置x轴的范围，后两个设置y轴的范围
clf %清空画布
A = magic(5)
imagesc(A) %变成一个带彩色的矩阵图
imagesc(A),colorbar,colormap gray %一个灰度图，带颜色图例条
%使用","号可以执行多个命令，依次执行
```

# p30控制语句:for,while,if
```Octave
v = zeros(10,1)
for i = 1:10,
    v(i) = 2^i;
end;

indices = 1:10
for i = indices,
    disp(i); %显示i
end;

i = 1;
while i <= 5,
    v(i) = 100;
    i = i + 1;
end;

i = 1;
while true,
    v(i) = 999;
    i = i + 1;
    if i == 6,
        break;%退出
    end;
end;

if v(1) == 1,
    disp('xxx');
elseif v(1) == 2,
    disp('xx)
else
    disp('x')
end;
exit; %退出Octave，quit也行


```

在Octave定义函数，你需要新建一个文件,文件名是：函数名.m
```
function y = squareThissNumber(x)

y = x^2;
```

```
%调用
addpath('c:\xxx') %添加这个路径后，就可以找到这个路径下的函数文件
squareThissNumber(2) %这时候就会输出4
```


也可以定义函数返回两个值
```
function [y1,y2] = squareAndCubeThisNumber(x)

y1 = x^2;
y2 = x^3;
```

# p31 向量化
求和操作可以看作是一个行向量 乘以 列向量
讲解到如何将梯度下降算法向量化

# p32 分类
将讨论logistic regression 逻辑回归算法
对于分类问题，使用线性回归算法是效果差的


# p33 logistc回归中假设函数的表示方法
在分类问题中，我们想要：0<=hΘ(x)<=1
hΘ(x) = Θ' * x，我们把Θ' * x作为函数g的参数：hΘ(x) = g(Θ' * x),
g(z) = 1/(1+e^-z),这个g叫做sigmoid函数，或叫logistic函数，这个函数的图像类似这样：ʃ   纵轴范围从0到1
hΘ(x) = p(y=1|x;Θ)  表示给定某个x，在参数为Θ下，y为1的概率

如果y只有0和1两个结果，那么：
p(y=1|x;Θ) + p(y=0|x;Θ) = 1

# p34
讲解decision boundary 决策边界的概念，帮助我们了解 logistc回归的假设函数在计算什么
我们根据hΘ(x) = g(Θ' * x) 这个概率是否大于等于0.5来判断结果是否是1还是0，根据g(z) = 1/(1+e^-z)可以知道Θ' * x >= 0时，判断结果为1

通过Θ' * x >= 0 ，我们可以可视化的在一个简单的例子中画出一条分界线（见视频较为直观）
通过构建多项式，我们可以得到各种形状的决策边界

# p35 如何拟合logistic回归模型的参数θ
要得到参数θ，我们想要定义用来拟合参数的代价函数（cost function）或优化函数（optimization objective）

定义代价函数
J(θ) = 1/m * i=1 Σ m * cost(hθ(x^(i),y))

在线性回归中 cost(hθ(x^(i),y)) = 1/2 * (hθ(x^(i)) - y)^2
由于hθ(x^(i))不是线性的，他在这里是sigmoid函数（1/(1+e^-z)），所以求差方的方式，也就是J(θ)是一个凸函数的方式，不适用（这里可以想象一下，如果假设函数是线性，那么肯定会有一个趋势，使得预测的值跟目标值的差最小，这个趋势就是通过J(θ)是一个凸函数来确定底部在哪的）
不适用是因为这时候画出的是一个非凸函数，他有很多局部低点

我们定义一个适合logistic回归的代价函数
cost(hθ(x^(i),y))：当y = 1时，为-log(hθ(x));当y = 0时，为-log(1-hθ(x));

logZ的图像类似这样：༼ 跨越一四象限，与横轴交与x为1的点

这里我再一次认识了代价函数，不管是平方差还是这里这个代价函数，只要离正确的结果远，或者可以算猜错了，那么J(θ)的值就会很大，相当于代价很大，所以选择代价小的值的情况，我们就找到了合适的θ

# p36 使用梯度下降最小化代价函数
logistic回归的代价函数可以根据上面y为0和1两种情况，合并起来写成一个公式：
cost(hθ(x^(i),y)) = -y * -log(hθ(x)); - (1 - y) * -log(hθ(x));

线性回归跟logistic回归的代价函数的梯度下降算法是同一个公式（连导数项都一样），但要注意的是hθ(x)不一样，
hθ(x)，在线性回归中是θ'x,在logistic回归中是1/(1+e^-z)

# p37 高级的优化算法
更适合解决大型的机器学习问题

除了梯度下降算法，我们还是可以使用：
Conjugate gradient 共轭梯度法
BFGS
L-BFGS

这三种算法很复杂（作者说的），一般具备这些优点：不需要手动设置α，普遍比梯度下降算法快；缺点：太复杂
作者使用了很多年以后才理解这些算法的细节，表达说你不需要真正理解他们你也能用好这些算法





（见视频）用Octave定义一个代价函数costFunction后，我们可以调用高级的优化函数fminunc,它在Octave中表示minimization unconstrained 无约束最小化函数
```
options = optimset('GradObj','on','MaxIter','100') %表示开启梯度算法，迭代100次
initialTheta = zeros(2,1)
[optTheta,functionVal,exitFlag] = fminunc(@costFunction,initialTheta,options)  %exitFlag 表示结果是否收敛，functionVal为代价函数的值
``` 

# p38 多元分类
一对多的分类算法：
就是将其中一类归为一种，其余类归为一种。按照这种方法依次计算所有类

然后想预测x属于哪个类，就选择可信度最高的那个hθ^(i)(x)


# p39 过度拟合问题
bias 偏差、偏见

|high bias  | just right |   high overfitting|
|---|---|---|
|高偏差|刚好|过度拟合|

过度拟合就是得到的预测函数可以穿过每一个训练点，为了“完美”的拟合说不定得到的不是一个合理的预测函数

解决过度拟合问题的方法：
第一种 减少特征
人工决定要选择什么样的特征，减少变量
模型选择算法（会自动选择合适的算法）

第二种 正则化
减少量级
θ的大小

# p40
更小的θ意味着更简单的假设函数

我们现在修改代价函数：
J(θ) = 1/m * i=1 Σ m * cost(hθ(x^(i),y)) + λ * (i=1 Σ m)θj^2，
λ * i=1 Σ m * θj^2 这个就是增加的正则化项，目的就是减少每一个参数θ，如果λ太大，将会导致“惩罚”太大，从而使得所有的参数θ都趋于0，这样的话就预测函数就高偏差了

# p41 线性回归的正则化
添加正规化后的梯度算法（见视频）
直观上看，梯度下降中的θ更新函数，可以看出每次迭代θ都会缩小一点，并沿斜率发现递减（这里还是看视频直观，我不想照着抄公式了）

如果选择正规方程求θ的话：
原本公式是：θ = (X^T * X)^(-1) * X^T *y，
现在（看视频）打字不好画，在07:12

# p42 logistic回归的正则化
同样也是代价函数增加一个正则化项，λ/2m * (i=1 Σ m)θj^2,来保持参数θ较小

# p43 非线性假设
介绍神经网络（Neural Network）
在特征太多的情况下，使用线性回归或者logistic回归，其预测函数可能面临由于多元导致的性能计算问题，且计算时间是呈指数增长

比如识别一辆车，对于一个50*50像素的图片，他有2500个像素点，意味着有2500个特征（我们可以通过对这些特征进行logistic回归得到预测函数，但是效率很低）（对于灰度图片是2500，对于rgb图片就是7500个特征了）
如果我们要通过包含所有的二次项特征（xi * xj）来得到非线性假设，那么大约有3百万个特征 

# p44
通过一些例子讲述，我们的大脑可以通过不同的传感器学会如何处理这些传感器的带给我们的信号数据（比如用舌头看东西）

# p45 神经网络模型
作者提供一个简单的神经元模型（图见视频），通过输入变量，传递给类似神经元的东西，神经元输出一个预测函数（该预测函数在这里为sigmoid），所以这个模型叫做带有sigmoid或者logistic激活函数的人工神经元
激活函数在神经网络中指的是非线性函数g(z),
g(z) = 1/(1+e^(-z))
在这个简单模型中，偏置单元一般省略（bias unit,这个按我理解就是调节用的）

模型的权重（weights）和模型的参数是一个意思

网络中的第一层称为输入层，我们在这一层输入特征值
最后一层称为输出层
中间那些称为隐藏层

激活项：一个具体神经元计算后得出的数值

ai^(j)代表第j层第i个神经元
θ^(j) 代表第j层到第j+1层的权重控制方法之矩阵的映射（matrix of weights controlling function mapping）（要理解这个矩阵的含义，可以见视频08:35）
j层有n个变量，θ^(j)矩阵就有n+1列（多出的一项是bias unit这项）;j+1层有m个变量，θ^(j)矩阵就有m行

    启示：对我们大脑自身，多练习，才能得到更好的参数，并且把参数记下。“聪明”，只是计算的得快，不聪明，慢慢算也能算出正确答案，得到好的结果。总结一句话就是练习很重要

# p46
如何对神经网络进行高效计算及其向量化的实现方法

单看倒数第二层和第一层，会发现跟logistic回归算法相同，不同之处只是在于logistic中变量是x1,x2,...;而神经网络中，变量是a1^(2),a2^(2),...这种计算而来的值

    思考：非线性假设由于特征量大（多项变量，如果x1*x2，x1*x2*x3），所以不用传统的logistc算法，所以我们引入“网”的概念，将多项变量拆分成一个个单变量。这种方法是否更高效目前我还没直观上的感受。

这种网的结构，相当于自己训练自己，得到一些不同的特征，作者描述这情况下我们能得到更好的假设

# p47 例子与直觉理解1
通过单一层网络的例子解释一个AND或者OR运算大概怎么来的（权重如何确定可以参考之前的梯度下降算法）

# p48 例子与直觉理解2
通过介绍 x1 AND x2、(NOT x1) AND (NOT x2)，x1 OR x2来组合得到 x1 XNOR x2

通过这个例子，可以很直观的感受到，通过神经元的不同作用，可以衍生出意想不到却又符合逻辑的结果

# p49 多元分类
通过增加输出，之前的2元分类是输出一个0或者1，现在多元分类是输出一个由0，1构成的向量。
使用的也是一对多法，通过区分单一物体与其他物体的区别就可以了

# p50 神经网络的代价函数
与logistic回归用的代价函数的一般形式相同，但由于不只有一个逻辑回归输出单元，而是k个输出，所以具体公式有所变化（见视频吧...）

# p51 反向传播算法
让神经网络的代价函数最小化的算法：back propagation algorithm 反向传播算法

通过计算最后一层的误差（通过目前权重得到的预测值，与结果值之间差），反向推出前面每一层的误差（公式见视频，通过sigmoid函数的导数，结合上一层的权重，可以倒推出上一层的误差值）
这些误差（Δ）会被用来计算代价函数的偏导数（这里是按我的理解进行复述）

    激活函数，在这里我对激活函数有了一个更好的理解，激活函数就相当于一个处理阈值的函数，阈值通过输入值（或是计算而来的隐藏层的激活项的值）决定是否为1还是0（这里的激活函数指sigmoid函数）

（看不懂证明过程，只知道公式好复杂）：通过一系列计算，得到代价函数对于权重矩阵中每个权重的偏导数

如果忽略正则化项，那么可以证明代价函数的偏导数：( ∂/∂θij^(l) )J(θ) = aj^(l) * δi^(l + 1)

理解一下这个（p51 09:53）：
Δij^(l) := Δij^(l) + aj^(l) * δi^(l + 1)
首先明确：Δij^(l) 会被用来计算 J(θ)的偏导数：( ∂/∂θij^(l) )J(θ)    （关于这点我在p54中的总结会提到，这里是我之前看p51时没弄清，之后留下的补充）
从公式上理解：就是将i从1开始，m个训练样本，Δij^(l)就是第i个样本的第l层的第j个节点的 代价函数在这里的偏导数 之和；
但是为什么要求所有样本在同样某一点的偏导数之和，我不理解

# p52 理解反向传播算法
误差项Δ就是代价函数关于这些计算出来的中间项的偏导数

反向传播与正向传播原理类似，见视频10:44
这里计算前一层的Δ时忽略了要乘以一个导数项，但不影响作者想表达的意思

# p53 
很多优化算法需要我们将矩阵展开为向量，所以这节课学习矩阵和向量的相互转换
```
%矩阵和向量的相互转换
V = [A(:),B(:)]
C = reshape(V(n:m),r,c) %取出向量V中第n~m个，以r为行，c为列得到一个矩阵
% 这里ABC是矩阵，V是向量
```

# p54 梯度检测
反向传播算法有很多细节，容易出错，并且难以发现，所以我们需要梯度检测来帮我们解决这种问题，具体公式见视频

执行步骤：
- 实现反向传播算法，计算得出DVec(也就是展开的D^(1),D^(2),D^(3))
- 执行 numerical gradient check计算得出gradApprox
- 确保他们的值相近
- 关闭梯度检测，使用反向传播算法进行训练（记得关掉！）


思考：这个神经网络过程中：假设函数是什么，DVec是什么，反向传播什么时候用?

按我理解描述一下过程，首先构建θ矩阵，一层一个θ矩阵；然后通过正向传播，输入训练样本的值得到输出值；输出值跟训练样本的结果对比，得到δ，也就是偏差项，然后使用反向传播倒推出每一层的偏差项(除了第一层，输入层)；通过偏差项可以算出代价函数的偏导数，然后再用梯度下降或者其他方法求得θ

我再捋一遍：
神经网络的假设函数是什么，神经网络的最终输出结果：hθ(x) = 1/(1+e^(-θ^Tx))
代价函数是什么：见视频p50
    反向传播算法，是为了优化代价函数：我们要得到代价函数的最小值，我们就需要计算两个东西：J(θ) 和其偏导数，这两东西可以用于梯度下降算法或者其他优化后的算法。
    具体做法是计算出各个误差项δ（公式见p51 04:36）,然后经过一系列数学证明，我们得到与δ有关的一个简化版的 J(θ)的偏导数公式，这样可以帮助我们更快的计算出偏导数

DVec是什么，是个向量，我解释向量的元素之一，D^(1)：跟第一层的代价函数的偏导数有关，进而跟Δ有关，主要作用是加了正则化项，可以见视频p51 10:49
一但算出D项，我们可以得到J(θ)的偏导数跟D有关：( ∂/∂θij^(l) )J(θ) = Dij^(l)

# p55 随机初始化
对于神经网络，初始化参数设置全为0的话，可以证明得到：同一个神经元对于下一层的n个神经元的权重是一样的，这样的结果就是在神经网络中我们计算不出什么有趣的结果

所以在初始化的时候使用随机参数，生成一个随机数在[-ε,ε]之间

```Octave
rand(10,11) %会生成一个10*11的随机矩阵

Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
```

# p56 总结训练一个神经网络的步骤
在训练之前，我们需要选择一种网络架构，也就是需要几层，每层多少个神经元。隐藏层一般默认只有一层。如果你想有多个隐藏层，那么默认每个隐藏层的神经元数量是相等的（通常来说数量越多越好）

1.随机参数化权重θ，权重值接近于零
2.实现前向传播算法，同过样本特征值x，算出y这个结果值（hθ(x^(i))）
3.实现代价函数J(θ)
4.实现反向传播算法，算出代价函数的偏导数
5.用梯度检测来比较这些偏导数是否相近，相近就正常
6.禁止梯度检测（因为计算消耗性能），使用梯度下降或者其他更优的方法来最小化代价函数从而得到正确的θ

注意代价函数是个非凸函数，所以存在局部最小值，但一般来讲不是大问题，还是能得到不错的效果


# p57
介绍基于前面提到的算法，对于无人驾驶的应用效果

# p58
如果预测结果差距很大，怎么办：
- 获取更多训练样本（有时候原因并不是样本太少）
- 尝试选用更少的特征（来防止过拟合）
- 尝试添加更多特征
- 尝试添加多项式特征（x1^2,x2^2,x1x2...）
- 尝试添加，或者减少正则化参数λ的值

大多数人都是凭感觉选择上面的方法，可能在耗费大量时间资源之后还是达不到满意的效果。作者提供一些办法来排除掉不必要的选择：Machine learning diagnostic机器学习诊断法

诊断就是通过测试来预见算法是否有效，获取如何提高表现的指导方法

这个诊断方法也是需要花很多时间来实现和执行的（但这是值得的，能为你节省很多其他不必要的时间）

# p59
如何评价一个通过学习后得到的假设函数
如何防止过拟合和欠拟合的问题

我们知道不是说误差最小，就证明这是个好的假设函数，因为可能还存在过拟合的问题，过拟合的话，在新的训练样本上就不太准确了

将数据分成两部分，一部分作为训练集，另一部分作为测试集，一般按照7：3的比例（如果数据有规律，还需要打乱后再选择）

对于线性回归，用的验证方法是累加测试集得到的误差
对于logistic回归，先通过对测试集的验证结果进行0/1错误分类度量，再累计分类后的结果

# p60
怎么选择合适的多项式次数，这叫模型选择问题
这需要把数据分成训练集，验证集，测试集，典型比例是：6:2:2

通过选择不同多项式次数，得出不同的θ，用验证集进行验证(也是算误差，也就是代价函数的公式)，选择误差最小的，再根据测试集得到偏差结果判断效果

# p61
运行机器学习算法出现不理想多半是出现两种情况：
诊断偏差（bias）较大，也就是欠拟合问题
方差较大，也就是过拟合问题
弄清楚是哪种情况很重要（见视频04:43）

# p62
正则化如何影响偏差和方差 太小会过拟合，太大会欠拟合

选择λ也是设置一系列的值，然后分别根据代价函数算出θ，再通过验证集来评价它们。选出最好的再通过测试集来查看效果

# p63 学习曲线
通过总和前面的知识点，建立一个诊断方法

假设前提是确定了假设函数后，我们会发现：随着训练样本的增大，训练集的误差会越来越大，因为越来越难拟合；但是验证集和测试集的误差会越来越小。
样本越大越能获得更好的泛化表现（be better at generalizing to new examples）

欠拟合（high bias 高偏差）的情况下，随着样本的增大，验证集的误差从大到小，训练集误差从小到大，然后两条曲线在一定样本量后趋于直线并且两数据集的误差相近。
欠拟合问题可以从趋于直线后还是有很高的误差值，在这种情况下看出来。
所以高偏差的情况下，选用更多的训练集是没有用的。

过拟合（high variance 高方差）的情况下，随着训练样本的增大，训练集的误差会越来越大，原因还是因为越来越难拟合，但是总的训练集误差还是很小。验证集误差从大到小，但不会小的哪里去，不管样本怎么添加，误差还是很大。特点是，训练误差和验证误差之间有很大的差距。
在过拟合的情况下，添加更多的训练数据是有用的。

# p64