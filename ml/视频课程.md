学习笔记，以视频集数为标题，总结每集的收获和知识点

[黑马最热门的人工智能机器学习及机器视觉终于来了！从入门到精通（附赠课件资料+笔记](https://www.bilibili.com/video/BV1wy4y1T78o)
这个视频TensorFlow用的是1.x的版本，从网上资料来看，目前2.x版本中已经废弃了很多1.x的api，并且操作上更加简洁，所以这个视频我先暂时不看了

# p2学习笔记
## 深度学习与机器学习的区别
特征提取方面：
    机器学习需要自己提取特征，这需要大量领域专业知识；
    深度学习（通常由多个层组成），通过大量数据训练自动得到模型，适用于难提取特征的图像，语音，自然语言领域（应用场景）；

数据量方面：
    深度学习一般数据量越大结论越准确，而机器学习在一定数据量后达到一个相对稳定的准确率，并不会随着后面数据量的增大而表现更佳。
    深度学习需要的算力也比较大

算法代表
    机器学习：朴素贝叶斯、决策树
    深度学习：神经网络



个人总结：在容易提取特征的领域，采用机器学习的方法，通过手动提取特征，在效率和效果方面应该是表现不错的。深度学习需要的数据量应该较大，提取模型的成本也比较大。所以不能说 深度学习 就比 机器学习 优

深度学习框架：github start关注度历年来前二分别是TensorFlow，Caffe 



[[中英字幕]吴恩达机器学习系列课程](https://www.bilibili.com/video/BV164411b7dx)

笔记
# p1
机器学习应用领域广泛，如自动驾驶，基因测序，研究人脑思考方式，搜索引擎推荐，图片分类，识别垃圾邮件等

# p2
介绍一般对于机器学习的定义，给一个任务T,通过经验E,得到性能度量P(我认为算做正确的概率)
这课程会教很多不同类型的学习算法，最主要的两类是 监督学习(supervised learning)和无监督学习（其他的经常听到的有，强化学习，推荐系统等）
简单的说 监督学习是我们让机器学会处理某一件事；无监督学习是我们让机器自己学习

# p3 
回归问题，值是连续的
分类问题，值是离散的
总结：通过值去判断要用把问题归为哪一类（进而选择合适的算法）
这些属于监督学习的范围

# p4
将无监督学习
中监督学习的例子中，我们会被告知什么是良性肿瘤，什么是恶性的；
现在我们拿到一推数据，没人告诉我们这些数据的意义，这时候就属于用到无监督学习的范围了
提到 
聚类算法，将数据归为一个簇一个簇的（应用例子：谷歌新闻：每天收集大量新闻并分为各种专题；给一推基因数据让其分类，类型我们事先未知；根据邮件判断哪些人可能是朋友；通过客户数据找到不同的细分市场）
鸡尾酒会算法（应用例子：耳机降噪），实际上一行算法：[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x');
svd：singular value decomposition 奇异值分解（线性代数常规函数）


提到Octave、Matlab这样的软件
作者推荐使用Octave，在硅谷很多人会先用Octave建立软件原型，因为在Octave中实现这些学习算法的速度很快，在这个软件中，例如svd函数也内置了，不然如果自己用c++或者java库我们需要自己写很多代码，当在软件里可以运行时，我们再将其迁移到其他环境（java，c++等）下，这样效率更高（根据弹幕有歧义，说现在python可以很方便的现实功能）

# p5
了解监督学习的过程
1. Traning Set训练集 --输入到>> Learning Algorithm学习算法 --得到>> h(hypotheis)假设函数
2. 输入值通过->h->输出预测值
# p6 代价函数
如果假设函数是这个形式： hθ(x) = θ0 + θ1x;
通过找到最小的值：minimize_θ0θ0  J(θ0,θ0) =  (1/2m) * 0Σi=m (h(x^(i)) - y^(i))^2的平方差和来确定参数值 (这个公式算我手打的...可能不好看，我用_标识后面的符号在底部。。。)

这个1/2m是为了开导时抵消掉平方，对优化结果来说无影响（弹幕提供）
（微积分有点忘了，但是这里感悟是用积分方程可以减低计算量）
微积分有公式的，比如基本的导数公式中 x^u = u*x^(u-1)

J(θ0,θ1) 在这里就是代价函数Cost function，或者叫做lost function。这里这个具体的函数叫做squared error function

这个squared error function对大多数回归问题是个合理的选择（常用）

# p7 代价函数2
作者简化了一下函数：hθ(x) = θ1x;然后将x值代进代价函数中，把θ1作为变量
画出了θ1与结果的图像变化图（可以看到变化的规律，嗯...没什么，算是加深一下对公式作用的理解吧）

# p8 代价函数3
假设函数换回这个形式： hθ(x) = θ0 + θ1x;
然后画图

提到 contour plots等高线图
如果是将x带入，那么由θ0，θ1，该代价函数的值分别坐标x,y,z轴，由此组成的立体图像会呈现一个碗状，在平面中我们可以用等高线去表示

从目前简单的例子可以体会到如何一步步寻找最小值（目前使用眼睛观察的），这让我想起梯度下降，动量等模糊概念，这些概念的存在意义就是为了加速得到最小值。而不是先遍历所有可能（遍历所有的值，在这就是画出三维立体图）

多维度参数想可视化就没那么简单了

# p9 梯度下降
gradient descent梯度下降，是一个很常用的算法。不仅可用在最小化线性回归的代价函数上

按照两个参数来举例：θ0、θ1
大概思路：
首先给θ0、θ1分别一个初始值，随便什么值都行。例如θ0 = 0、θ1 = 0
不断改变θ0、θ1，使得 代价函数J(θ0、θ1)变小，直到找到最小值或局部最小值（这很明显跟初始位置及“山峰”形状有关）

梯度下降算法：
重复更新参数θj直至收敛
repeat until convergence{
    θj :=θj - α(∂/∂θj)J(θ0、θ1)  (simultaneously update j=0 and j=1)
}
在这就是同时更新θ0和θ1

:= 表示赋值（如果单纯用=，在这里是断言，会得到true或false）
α 学习率,是一个数值，在梯度下降中，意味着我们迈出多大的步子，值大意味着梯度下降很迅速
(∂/∂θj)J(θ0、θ1) 是一个导数项（没见过偏导数的话看一下下面提供的参考资料）  

(∂/∂x)f(x,y)，表示函数f(x,y)对变量x的偏导
(∂/∂y)f(x,y)，表示函数f(x,y)对变量y的偏导

参考资料
[第二节 偏导数](http://netedu.xauat.edu.cn/jpkc/netedu/jpkc/gdsx/homepage/5jxsd/51/513/5308/530802.htm)
在资料中可以了解到，求偏导数跟求导数方法一样，先把其他变量看成常量，再用求一元函数的导数的方法去求导

# p10 梯度下降算法里那个导数项的相关内容
derivative 导数
导数和偏导数是什么？（惨，大学数学给忘了）这里我百度了一下 [偏导数、微分、以及导数到底有什么关系和区别？](https://www.zhihu.com/question/265021971)


一个函数的导数，就是函数在图像上的斜率
偏导数，偏是局部的意思，一般是是指一个多元函数，其他变量都确定时，只对有剩余一个不确定的变量函数的导数。在几何意义上，就是一个点在任意确定的面上的切线的斜率。（想象一下，一个三维物体上的一个点，是不是有无数条切线，而二维平面图上，一条曲线是不是只有一条切线。所以求一条曲线的切线的斜率和求一个三维物体的其中一条切线的斜率就是导数和偏导数的区别）

在简化的代价函数J(θ1)中，对其θ1的偏导数就是 (∂/∂θ1)*J(θ1),这里是我个人理解的写法，一般不会这么表示，一般一元函数的导数写作J'(θ1)

α 学习率，如果太小，那么需要很多步才能到达局部低点；如果太大，可能会一次性越过最低点，导致无法收敛，也就是一直无法达到局部低点

随着θ1的更新，(∂/∂θ1)*J(θ1)作为斜率的值越来越小，所以θ1更新的幅度越来越小，最终我们会无限接近最低点。


## p1~p10 总结

对于一个线性的问题，
我们需要得到一个函数y=f(x),这样我们可以通过输入任意x得到答案y
这时候函数的形状可能有很多种，那么我们只能先假设，假设这个函数是直线，然后大概长这样：
f(x) = a + bx; a,b是一个固定的值，然后确定要用的损失函数，也就是代价函数，把a,b作为变量，通过h(a,b) 这个代价函数来确定a，b的值。

那么这里用什么形式的代价函数，用什么方法确定a，b的值，就是我们学习的重点了。
这几节课里我学习了squared error function在回归问题上作为代价函数效果不错，然后学习了梯度下降这种函数方法是如何来对这种代价函数进行处理的

所以目前我算是掌握了一个对于这种回归问题如何处理的整体思路。

    个人思考：
    目前感受到的就是算法、数学的魅力，但是智能还算不上，到不如说“自动”，就像你问计算机1+1，他跟你说等于2，那么分类，预测，只是相当于把1+1换成了更加复杂的东西，本质上还是计算方式

    那么神经网络，深度学习是不是毕竟接近我们印象中的智能呢？其实他也是一种算法，而我现在就在了解其具体的算法。这就是所谓的“人工智能”，跟人类的拥有复杂感情相比好像关系没那么明显或者说没有关系。但是仔细想想，大多数感情，感觉都是身体里的各种器官，激素的作用和变化引起“感觉”，“感觉”跟“人工智能”合在一起才是个完整的人。那么现在思路就更加清晰了，我在学的是“智能”，就是所谓的让计算机更加聪明的方法。所以重点在于“智能”，而不在于“人”上。“智能”目前是生物才具有的。所以研究神经网络的应用最接近“智能”了吧

# p11
这节课将代价函数带入并求偏导数的值（证明方法略）：

注意要同时更新θ0和θ1
repeat until convergence{
    θ0 :=θ0 - α * (1/m) * i=1 Σ m (hθ(xi)-yi)
    θ1 :=θ1 - α * (1/m) * i=1 Σ m (hθ(xi)-yi) * xi
}

xi代表训练集中第i个x的数据，m代表有训练集中有m个数据

用梯度下降法有个缺点就是得到的是局部底部，然而这里代价函数是线性回归方程，得到的三维图像是一个碗状的图形，这图形有个术语叫做convex function 凸函数

凸函数不会存在只得到局部最低点这个问题，它只有一个全局最优解

给这种梯度下降一个名字，叫做“Batch” Gradient Descent，Batch在这里表示每一步梯度都需要使用到所有的训练集数据（那个i=1 Σ m ）

# p12
提到矩阵与向量的概念,表达方式。（这个看视频，我不好表达）
矩阵，就像二维数组，维数就是行数*列数，书写形式有R^(2*2)

向量，就像一维数组，一个n*1的矩阵，可以写成R^n

# p13
矩阵加法，就是对应元素相加，并且得是相同结构的矩阵才能相加
矩阵和标量（就是实数）的乘法，就是每个对应的元素与标量相乘
# p14 矩阵乘法
先讲了个特殊例子， 矩阵跟向量的乘法：例中R^(3*2) x R^(2*1) 得到一个R^(3*1)的矩阵，那么看来要相乘的话，第一个矩阵的列数要跟第二个矩阵的行数相同

作者举了一个房子价格的例子，用矩阵跟向量的乘法，可以将不同房子大小这个变量发到矩阵中，配合价格函数构造出一个矩阵乘向量的模型（对这种计算的表达方式我觉得十分的miao），这样做的好处在于用更加简洁的公式表达了想法（相当于简化了代码,目前我具体感受不到）

# p15 矩阵与矩阵相乘
了解这个可以在线性回归中同时计算θ0和θ1而不用梯度下降函数（作者说的）

矩阵与矩阵相乘可以看作矩阵跟各个向量相乘的结果，拼起来（所以还是遵循一个规则：第一个矩阵的列数要跟第二个矩阵的行数相同）
通过举例多个预测价格函数（上一集将跟向量相乘时是举例一个价格函数），来体现矩阵与矩阵相乘的表达方式（miao啊又）

# p16
设计矩阵运算的一些特性：
不符合交换律（commutative）
符合结合律（associative）

单位矩阵（可以有多种维数的），只有Rii上的值为1，其他为0。表述为I(或者I_n*n),单位矩阵与矩阵相乘满足交换律  注意：交换后的单位矩阵的维数不一定跟原来的一致，切记

# p17
矩阵的逆运算(inverse operation)、矩阵的转置运算(transpose operation)

    A*A^-1 = I 这个A^-1就是矩阵A的逆矩阵。只有m*m的这种方阵才有逆矩阵 有一些特殊的方阵也是没用逆矩阵的，作者这里不讨论
不存在逆矩阵的矩阵有个专有名词叫做 奇异矩阵 singular matrix或者退化矩阵 degenerate matrix

A^T表示矩阵A的转置矩阵，具体表现为矩阵里的元素位置A_ij变成A_ji（第一行变成第一列，以此类推）

# p18
回到之前房屋价格预测的例子，如果这时候信息多了（特征量多了），原先只考虑房子大小跟价格的关系，现在可以考虑的因素有大小，楼层，房龄，房间数量。

那么重新定义一下：
n：特征数
x^(i)第i个训练集，是有一组特征值组成的向量
x^(i)_j 第i个训练集的第j个特征值（这里我写的格式不规范...）

代价函数变成了hθ(x1,x2,x3,x4) = θ0 + θ1x1 + θ2x2 + θ3x3 + θ4x4;(多元多变量线性回归假设)
通过构建 θ变量组成的向量 和x标量组成的向量，可以用来表示hθ(x1,x2,x3,x4)

# p19
    Hypothesis:hθ(x) = θ^T*x = θ0*x0 + θ1*x1 + θ2*x2 + ... + θn*xn  (这里θ和x分别是指向量)
    Parameter:θ0,θ1,...,θn (我们这里会用θ这个向量表示这一串变量)
    Cost function: J(θ0,θ1,...,θn) = (1/2m) * i=1Σm (hθ(x^(i)) - y^(i))^2   （同理J(θ0,θ1,...,θn)写成J(θ)）
 