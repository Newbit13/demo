{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "9f39d627c48f3cfe03bd5909798566c8d1df8bd6a58957f823d924d9f2b3892d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import h5py\r\n",
    "from lr_utils import load_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def load_dataset():\r\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\r\n",
    "    # print(type(train_dataset[\"train_set_y\"][:])) #<class 'numpy.ndarray'>\r\n",
    "    # print(np.array(train_dataset[\"train_set_y\"][:])) # 打印一个数组\r\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\r\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\r\n",
    "\r\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\r\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\r\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\r\n",
    "\r\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\r\n",
    "    # print(train_set_y_orig.shape) # (209,)\r\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0])) #将数组转成R^(1*n)的矩阵，也是一个二维数组\r\n",
    "    # print(train_set_y_orig.shape) # (1,209)\r\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\r\n",
    "    \r\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes = load_dataset()\r\n",
    "print(train_set_y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(209,)\n",
      "(1, 209)\n",
      "(1, 209)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# for i in range(len(train_set_x_orig)):\r\n",
    "#     plt.imshow(train_set_x_orig[i])\r\n",
    "# print(train_set_x_orig[index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "m_train = train_set_y.shape[1] #训练集里图片的数量。\r\n",
    "m_test = test_set_y.shape[1] #测试集里图片的数量。\r\n",
    "num_px = train_set_x_orig.shape[1] #训练、测试集里面的图片的宽度和高度（均为64x64）。\r\n",
    "\r\n",
    "#现在看一看我们加载的东西的具体情况\r\n",
    "# print (\"训练集的数量: m_train = \" + str(m_train))\r\n",
    "# print (\"测试集的数量 : m_test = \" + str(m_test))\r\n",
    "# print (\"每张图片的宽/高 : num_px = \" + str(num_px))\r\n",
    "# print (\"每张图片的大小 : (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\r\n",
    "# print (\"训练集_图片的维数 : \" + str(train_set_x_orig.shape))\r\n",
    "# print (\"训练集_标签的维数 : \" + str(train_set_y.shape))\r\n",
    "# print (\"测试集_图片的维数: \" + str(test_set_x_orig.shape))\r\n",
    "# print (\"测试集_标签的维数: \" + str(test_set_y.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练集的数量: m_train = 209\n",
      "测试集的数量 : m_test = 50\n",
      "每张图片的宽/高 : num_px = 64\n",
      "每张图片的大小 : (64, 64, 3)\n",
      "训练集_图片的维数 : (209, 64, 64, 3)\n",
      "训练集_标签的维数 : (1, 209)\n",
      "测试集_图片的维数: (50, 64, 64, 3)\n",
      "测试集_标签的维数: (1, 50)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#X_flatten = X.reshape(X.shape [0]，-1).T ＃X.T是X的转置\r\n",
    "#将训练集的维度降低并转置。\r\n",
    "train_set_x_flatten  = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\r\n",
    "#将测试集的维度降低并转置。\r\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\r\n",
    "print (\"训练集降维最后的维度： \" + str(train_set_x_flatten.shape))\r\n",
    "print (\"训练集_标签的维数 : \" + str(train_set_y.shape))\r\n",
    "print (\"测试集降维之后的维度: \" + str(test_set_x_flatten.shape))\r\n",
    "print (\"测试集_标签的维数 : \" + str(test_set_y.shape))\r\n",
    "print(train_set_x_flatten)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练集降维最后的维度： (12288, 209)\n",
      "训练集_标签的维数 : (1, 209)\n",
      "测试集降维之后的维度: (12288, 50)\n",
      "测试集_标签的维数 : (1, 50)\n",
      "[[ 17 196  82 ... 143  22   8]\n",
      " [ 31 192  71 ... 155  24  28]\n",
      " [ 56 190  68 ... 165  23  53]\n",
      " ...\n",
      " [  0  82 138 ...  85   4   0]\n",
      " [  0  80 141 ... 107   5   0]\n",
      " [  0  81 142 ... 149   0   0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_set_x = train_set_x_flatten / 255\r\n",
    "test_set_x = test_set_x_flatten / 255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def sigmoid(z):\r\n",
    "    \"\"\"\r\n",
    "    参数：\r\n",
    "        z  - 任何大小的标量或numpy数组。\r\n",
    "    \r\n",
    "    返回：\r\n",
    "        s  -  sigmoid（z）\r\n",
    "    \"\"\"\r\n",
    "    s = 1 / (1 + np.exp(-z))\r\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def initialize_with_zeros(dim):\r\n",
    "    \"\"\"\r\n",
    "        此函数为w创建一个维度为（dim，1）的0向量，并将b初始化为0。\r\n",
    "        \r\n",
    "        参数：\r\n",
    "            dim  - 我们想要的w矢量的大小（或者这种情况下的参数数量）\r\n",
    "        \r\n",
    "        返回：\r\n",
    "            w  - 维度为（dim，1）的初始化向量。\r\n",
    "            b  - 初始化的标量（对应于偏差）\r\n",
    "    \"\"\"\r\n",
    "    w = np.zeros(shape = (dim,1))\r\n",
    "    b = 0\r\n",
    "    #使用断言来确保我要的数据是正确的\r\n",
    "    assert(w.shape == (dim, 1)) #w的维度是(dim,1)\r\n",
    "    assert(isinstance(b, float) or isinstance(b, int)) #b的类型是float或者是int\r\n",
    "    \r\n",
    "    return (w , b)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def propagate(w, b, X, Y):\r\n",
    "    \"\"\"\r\n",
    "    实现前向和后向传播的成本函数及其梯度。\r\n",
    "    参数：\r\n",
    "        w  - 权重，大小不等的数组（num_px * num_px * 3，1）\r\n",
    "        b  - 偏差，一个标量\r\n",
    "        X  - 矩阵类型为（num_px * num_px * 3，训练数量）\r\n",
    "        Y  - 真正的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1,训练数据数量)\r\n",
    "\r\n",
    "    返回：\r\n",
    "        cost- 逻辑回归的负对数似然成本\r\n",
    "        dw  - 相对于w的损失梯度，因此与w相同的形状\r\n",
    "        db  - 相对于b的损失梯度，因此与b的形状相同\r\n",
    "    \"\"\"\r\n",
    "    m = X.shape[1]\r\n",
    "        \r\n",
    "    #正向传播\r\n",
    "    A = sigmoid(np.dot(w.T,X) + b) #计算激活值，请参考公式2。\r\n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A))) #计算成本，请参考公式3和4。\r\n",
    "\r\n",
    "    #反向传播\r\n",
    "    dw = (1 / m) * np.dot(X, (A - Y).T) #请参考视频中的偏导公式。\r\n",
    "    db = (1 / m) * np.sum(A - Y) #请参考视频中的偏导公式。\r\n",
    "\r\n",
    "    #使用断言确保我的数据是正确的\r\n",
    "    assert(dw.shape == w.shape)\r\n",
    "    assert(db.dtype == float)\r\n",
    "    cost = np.squeeze(cost) #把维度为1的去掉，半懂\r\n",
    "    assert(cost.shape == ())\r\n",
    "\r\n",
    "    #创建一个字典，把dw和db保存起来。\r\n",
    "    grads = {\r\n",
    "                \"dw\": dw,\r\n",
    "                \"db\": db\r\n",
    "             }\r\n",
    "    return (grads , cost)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}