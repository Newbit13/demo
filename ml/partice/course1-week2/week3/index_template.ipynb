{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "9f39d627c48f3cfe03bd5909798566c8d1df8bd6a58957f823d924d9f2b3892d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from lr_utils import load_dataset\r\n",
    "\r\n",
    "train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes = load_dataset()\r\n",
    "\r\n",
    "m_train = train_set_y.shape[1] #训练集里图片的数量。\r\n",
    "m_test = test_set_y.shape[1] #测试集里图片的数量。\r\n",
    "num_px = train_set_x_orig.shape[1] #训练、测试集里面的图片的宽度和高度（均为64x64）。\r\n",
    "\r\n",
    "#现在看一看我们加载的东西的具体情况\r\n",
    "print (\"训练集的数量: m_train = \" + str(m_train))\r\n",
    "print (\"测试集的数量 : m_test = \" + str(m_test))\r\n",
    "print (\"每张图片的宽/高 : num_px = \" + str(num_px))\r\n",
    "print (\"每张图片的大小 : (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\r\n",
    "print (\"训练集_图片的维数 : \" + str(train_set_x_orig.shape))\r\n",
    "print (\"训练集_标签的维数 : \" + str(train_set_y.shape))\r\n",
    "print (\"测试集_图片的维数: \" + str(test_set_x_orig.shape))\r\n",
    "print (\"测试集_标签的维数: \" + str(test_set_y.shape))\r\n",
    "\r\n",
    "#将训练集的维度降低并转置。\r\n",
    "train_set_x_flatten  = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\r\n",
    "#将测试集的维度降低并转置。\r\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\r\n",
    "\r\n",
    "print (\"训练集降维最后的维度： \" + str(train_set_x_flatten.shape))\r\n",
    "print (\"训练集_标签的维数 : \" + str(train_set_y.shape))\r\n",
    "print (\"测试集降维之后的维度: \" + str(test_set_x_flatten.shape))\r\n",
    "print (\"测试集_标签的维数 : \" + str(test_set_y.shape))\r\n",
    "\r\n",
    "train_set_x = train_set_x_flatten / 255\r\n",
    "test_set_x = test_set_x_flatten / 255\r\n",
    "\r\n",
    "def sigmoid(z):\r\n",
    "    \"\"\"\r\n",
    "    参数：\r\n",
    "        z  - 任何大小的标量或numpy数组。\r\n",
    "\r\n",
    "    返回：\r\n",
    "        s  -  sigmoid（z）\r\n",
    "    \"\"\"\r\n",
    "    s = 1 / (1 + np.exp(-z))\r\n",
    "    return s\r\n",
    "\r\n",
    "def initialize_with_zeros(dim):\r\n",
    "    \"\"\"\r\n",
    "        此函数为w创建一个维度为（dim，1）的0向量，并将b初始化为0。\r\n",
    "\r\n",
    "        参数：\r\n",
    "            dim  - 我们想要的w矢量的大小（或者这种情况下的参数数量）\r\n",
    "\r\n",
    "        返回：\r\n",
    "            w  - 维度为（dim，1）的初始化向量。\r\n",
    "            b  - 初始化的标量（对应于偏差）\r\n",
    "    \"\"\"\r\n",
    "    w = np.zeros(shape = (dim,1))\r\n",
    "    b = 0\r\n",
    "    #使用断言来确保我要的数据是正确的\r\n",
    "    assert(w.shape == (dim, 1)) #w的维度是(dim,1)\r\n",
    "    assert(isinstance(b, float) or isinstance(b, int)) #b的类型是float或者是int\r\n",
    "\r\n",
    "    return (w , b)\r\n",
    "\r\n",
    "def propagate(w, b, X, Y):\r\n",
    "    \"\"\"\r\n",
    "    实现前向和后向传播的成本函数及其梯度。\r\n",
    "    参数：\r\n",
    "        w  - 权重，大小不等的数组（num_px * num_px * 3，1）\r\n",
    "        b  - 偏差，一个标量\r\n",
    "        X  - 矩阵类型为（num_px * num_px * 3，训练数量）\r\n",
    "        Y  - 真正的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1,训练数据数量)\r\n",
    "\r\n",
    "    返回：\r\n",
    "        cost- 逻辑回归的负对数似然成本\r\n",
    "        dw  - 相对于w的损失梯度，因此与w相同的形状\r\n",
    "        db  - 相对于b的损失梯度，因此与b的形状相同\r\n",
    "    \"\"\"\r\n",
    "    m = X.shape[1]\r\n",
    "\r\n",
    "    #正向传播\r\n",
    "    A = sigmoid(np.dot(w.T,X) + b) #计算激活值，请参考公式2。\r\n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A))) #计算成本，请参考公式3和4。\r\n",
    "\r\n",
    "    #反向传播\r\n",
    "    dw = (1 / m) * np.dot(X, (A - Y).T) #请参考视频中的偏导公式。\r\n",
    "    db = (1 / m) * np.sum(A - Y) #请参考视频中的偏导公式。\r\n",
    "\r\n",
    "    #使用断言确保我的数据是正确的\r\n",
    "    assert(dw.shape == w.shape)\r\n",
    "    assert(db.dtype == float)\r\n",
    "    # cost = np.squeeze(cost) # np.squeeze可以把 1*m的矩阵变成长度为m的数组，但是这里的cost已经是个数值了，不是矩阵\r\n",
    "    # assert(cost.shape == ())\r\n",
    "    assert(isinstance(cost, float))\r\n",
    "\r\n",
    "    #创建一个字典，把dw和db保存起来。\r\n",
    "    grads = {\r\n",
    "                \"dw\": dw,\r\n",
    "                \"db\": db\r\n",
    "             }\r\n",
    "    return (grads , cost)\r\n",
    "\r\n",
    "def optimize(w , b , X , Y , num_iterations , learning_rate , print_cost = False):\r\n",
    "    \"\"\"\r\n",
    "    此函数通过运行梯度下降算法来优化w和b\r\n",
    "\r\n",
    "    参数：\r\n",
    "        w  - 权重，大小不等的数组（num_px * num_px * 3，1）\r\n",
    "        b  - 偏差，一个标量\r\n",
    "        X  - 维度为（num_px * num_px * 3，训练数据的数量）的数组。\r\n",
    "        Y  - 真正的“标签”矢量（如果非猫则为0，如果是猫则为1），矩阵维度为(1,训练数据的数量)\r\n",
    "        num_iterations  - 优化循环的迭代次数\r\n",
    "        learning_rate  - 梯度下降更新规则的学习率\r\n",
    "        print_cost  - 每100步打印一次损失值\r\n",
    "\r\n",
    "    返回：\r\n",
    "        params  - 包含权重w和偏差b的字典\r\n",
    "        grads  - 包含权重和偏差相对于成本函数的梯度的字典\r\n",
    "        成本 - 优化期间计算的所有成本列表，将用于绘制学习曲线。\r\n",
    "\r\n",
    "    提示：\r\n",
    "    我们需要写下两个步骤并遍历它们：\r\n",
    "        1）计算当前参数的成本和梯度，使用propagate（）。\r\n",
    "        2）使用w和b的梯度下降法则更新参数。\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    costs = []\r\n",
    "\r\n",
    "    for i in range(num_iterations):\r\n",
    "\r\n",
    "        grads, cost = propagate(w, b, X, Y)\r\n",
    "\r\n",
    "        dw = grads[\"dw\"]\r\n",
    "        db = grads[\"db\"]\r\n",
    "\r\n",
    "        w = w - learning_rate * dw\r\n",
    "        b = b - learning_rate * db\r\n",
    "\r\n",
    "        #记录成本\r\n",
    "        if i % 100 == 0:\r\n",
    "            costs.append(cost)\r\n",
    "        #打印成本数据\r\n",
    "        if (print_cost) and (i % 100 == 0):\r\n",
    "            print(\"迭代的次数: %i ， 误差值： %f\" % (i,cost))\r\n",
    "\r\n",
    "    params  = {\r\n",
    "                \"w\" : w,\r\n",
    "                \"b\" : b }\r\n",
    "    grads = {\r\n",
    "            \"dw\": dw,\r\n",
    "            \"db\": db } \r\n",
    "    return (params , grads , costs)\r\n",
    "\r\n",
    "def predict(w , b , X ):\r\n",
    "    \"\"\"\r\n",
    "    使用学习逻辑回归参数logistic （w，b）预测标签是0还是1，\r\n",
    "\r\n",
    "    参数：\r\n",
    "        w  - 权重，大小不等的数组（num_px * num_px * 3，1）\r\n",
    "        b  - 偏差，一个标量\r\n",
    "        X  - 维度为（num_px * num_px * 3，训练数据的数量）的数据\r\n",
    "\r\n",
    "    返回：\r\n",
    "        Y_prediction  - 包含X中所有图片的所有预测【0 | 1】的一个numpy数组（向量）\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    m  = X.shape[1] #图片的数量\r\n",
    "    Y_prediction = np.zeros((1,m)) \r\n",
    "    w = w.reshape(X.shape[0],1)\r\n",
    "\r\n",
    "    #计预测猫在图片中出现的概率\r\n",
    "    A = sigmoid(np.dot(w.T , X) + b)\r\n",
    "    for i in range(A.shape[1]):\r\n",
    "        #将概率a [0，i]转换为实际预测p [0，i]\r\n",
    "        Y_prediction[0,i] = 1 if A[0,i] > 0.5 else 0\r\n",
    "    #使用断言\r\n",
    "    assert(Y_prediction.shape == (1,m))\r\n",
    "\r\n",
    "    return Y_prediction\r\n",
    "\r\n",
    "def model(X_train , Y_train , X_test , Y_test , num_iterations = 2000 , learning_rate = 0.5 , print_cost = False):\r\n",
    "    \"\"\"\r\n",
    "    通过调用之前实现的函数来构建逻辑回归模型\r\n",
    "\r\n",
    "    参数：\r\n",
    "        X_train  - numpy的数组,维度为（num_px * num_px * 3，m_train）的训练集\r\n",
    "        Y_train  - numpy的数组,维度为（1，m_train）（矢量）的训练标签集\r\n",
    "        X_test   - numpy的数组,维度为（num_px * num_px * 3，m_test）的测试集\r\n",
    "        Y_test   - numpy的数组,维度为（1，m_test）的（向量）的测试标签集\r\n",
    "        num_iterations  - 表示用于优化参数的迭代次数的超参数\r\n",
    "        learning_rate  - 表示optimize（）更新规则中使用的学习速率的超参数\r\n",
    "        print_cost  - 设置为true以每100次迭代打印成本\r\n",
    "\r\n",
    "    返回：\r\n",
    "        d  - 包含有关模型信息的字典。\r\n",
    "    \"\"\"\r\n",
    "    w , b = initialize_with_zeros(X_train.shape[0])\r\n",
    "\r\n",
    "    parameters , grads , costs = optimize(w , b , X_train , Y_train,num_iterations , learning_rate , print_cost)\r\n",
    "\r\n",
    "    #从字典“参数”中检索参数w和b\r\n",
    "    w , b = parameters[\"w\"] , parameters[\"b\"]\r\n",
    "\r\n",
    "    #预测测试/训练集的例子\r\n",
    "    Y_prediction_test = predict(w , b, X_test)\r\n",
    "    Y_prediction_train = predict(w , b, X_train)\r\n",
    "\r\n",
    "    #打印训练后的准确性\r\n",
    "    print(\"训练集准确性：\"  , format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100) ,\"%\")\r\n",
    "    print(\"测试集准确性：\"  , format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100) ,\"%\")\r\n",
    "\r\n",
    "    d = {\r\n",
    "            \"costs\" : costs,\r\n",
    "            \"Y_prediction_test\" : Y_prediction_test,\r\n",
    "            \"Y_prediciton_train\" : Y_prediction_train,\r\n",
    "            \"w\" : w,\r\n",
    "            \"b\" : b,\r\n",
    "            \"learning_rate\" : learning_rate,\r\n",
    "            \"num_iterations\" : num_iterations }\r\n",
    "    return d\r\n",
    "\r\n",
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\r\n",
    "\r\n",
    "#绘制图\r\n",
    "costs = np.squeeze(d['costs'])\r\n",
    "plt.plot(costs)\r\n",
    "plt.ylabel('cost')\r\n",
    "plt.xlabel('iterations (per hundreds)')\r\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练集的数量: m_train = 209\n",
      "测试集的数量 : m_test = 50\n",
      "每张图片的宽/高 : num_px = 64\n",
      "每张图片的大小 : (64, 64, 3)\n",
      "训练集_图片的维数 : (209, 64, 64, 3)\n",
      "训练集_标签的维数 : (1, 209)\n",
      "测试集_图片的维数: (50, 64, 64, 3)\n",
      "测试集_标签的维数: (1, 50)\n",
      "训练集降维最后的维度： (12288, 209)\n",
      "训练集_标签的维数 : (1, 209)\n",
      "测试集降维之后的维度: (12288, 50)\n",
      "测试集_标签的维数 : (1, 50)\n",
      "迭代的次数: 0 ， 误差值： 0.693147\n",
      "迭代的次数: 100 ， 误差值： 0.584508\n",
      "迭代的次数: 200 ， 误差值： 0.466949\n",
      "迭代的次数: 300 ， 误差值： 0.376007\n",
      "迭代的次数: 400 ， 误差值： 0.331463\n",
      "迭代的次数: 500 ， 误差值： 0.303273\n",
      "迭代的次数: 600 ， 误差值： 0.279880\n",
      "迭代的次数: 700 ， 误差值： 0.260042\n",
      "迭代的次数: 800 ， 误差值： 0.242941\n",
      "迭代的次数: 900 ， 误差值： 0.228004\n",
      "迭代的次数: 1000 ， 误差值： 0.214820\n",
      "迭代的次数: 1100 ， 误差值： 0.203078\n",
      "迭代的次数: 1200 ， 误差值： 0.192544\n",
      "迭代的次数: 1300 ， 误差值： 0.183033\n",
      "迭代的次数: 1400 ， 误差值： 0.174399\n",
      "迭代的次数: 1500 ， 误差值： 0.166521\n",
      "迭代的次数: 1600 ， 误差值： 0.159305\n",
      "迭代的次数: 1700 ， 误差值： 0.152667\n",
      "迭代的次数: 1800 ， 误差值： 0.146542\n",
      "迭代的次数: 1900 ， 误差值： 0.140872\n",
      "训练集准确性： 99.04306220095694 %\n",
      "测试集准确性： 70.0 %\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15400/931579776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;31m#绘制图\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15400/931579776.py\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, num_iterations, learning_rate, print_cost)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mtempA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_prediction_test\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtempA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}